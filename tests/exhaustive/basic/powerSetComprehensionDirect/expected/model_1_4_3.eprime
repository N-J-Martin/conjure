language ESSENCE' 1.0

given n: int
given a: int
given b: int
find x_Occurrence: matrix indexed by [int(a..b)] of bool
find x_ExplicitVarSizeWithFlags_Flags: matrix indexed by [int(1..1 + (b - a))] of bool
find x_ExplicitVarSizeWithFlags_Values: matrix indexed by [int(1..1 + (b - a))] of int(a..b)
such that
    and([and([x_Occurrence[t_ExplicitVarSizeWithMarker_Values[q16]]
                  | q16 : int(1..1 + (b - a)), q16 <= t_ExplicitVarSizeWithMarker_Marker])
         ->
         sum([t_ExplicitVarSizeWithMarker_Values[q17]
                  | q17 : int(1..1 + (b - a)), q17 <= t_ExplicitVarSizeWithMarker_Marker])
         <= 6
             | t_ExplicitVarSizeWithMarker_Marker : int(0..1 + (b - a)),
               t_ExplicitVarSizeWithMarker_Values : matrix indexed by [int(1..1 + (b - a))] of int(a..b),
               and([q12 + 1 <= t_ExplicitVarSizeWithMarker_Marker ->
                    t_ExplicitVarSizeWithMarker_Values[q12] < t_ExplicitVarSizeWithMarker_Values[q12 + 1]
                        | q12 : int(1..1 + (b - a) - 1)]),
               and([q13 > t_ExplicitVarSizeWithMarker_Marker -> t_ExplicitVarSizeWithMarker_Values[q13] = a
                        | q13 : int(1..1 + (b - a))])]),
    n <= sum([toInt(x_Occurrence[q1]) | q1 : int(a..b)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q2 + 1] ->
         x_ExplicitVarSizeWithFlags_Values[q2] < x_ExplicitVarSizeWithFlags_Values[q2 + 1]
             | q2 : int(1..1 + (b - a) - 1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q3] = false -> x_ExplicitVarSizeWithFlags_Values[q3] = a
             | q3 : int(1..1 + (b - a))]),
    and([x_ExplicitVarSizeWithFlags_Flags[q4 + 1] -> x_ExplicitVarSizeWithFlags_Flags[q4]
             | q4 : int(1..1 + (b - a) - 1)]),
    n <= sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q5]) | q5 : int(1..1 + (b - a))]),
    and([x_ExplicitVarSizeWithFlags_Flags[q8] -> x_Occurrence[x_ExplicitVarSizeWithFlags_Values[q8]]
             | q8 : int(1..1 + (b - a))]),
    and([x_Occurrence[q9] ->
         or([x_ExplicitVarSizeWithFlags_Flags[q11] /\ x_ExplicitVarSizeWithFlags_Values[q11] = q9
                 | q11 : int(1..1 + (b - a))])
             | q9 : int(a..b)])

