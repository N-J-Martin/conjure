language ESSENCE' 1.0

given n: int
given a: int
given b: int
find x_ExplicitVarSizeWithDummy: matrix indexed by [int(1..1 + (b - a))] of int(a..b + 1)
such that
    and([and([or([x_ExplicitVarSizeWithDummy[q13] != b + 1 /\
                  x_ExplicitVarSizeWithDummy[q13] = t_ExplicitVarSizeWithFlags_Values[q11]
                      | q13 : int(1..1 + (b - a))])
                  | q11 : int(1..1 + (b - a)), t_ExplicitVarSizeWithFlags_Flags[q11]])
         ->
         sum([t_ExplicitVarSizeWithFlags_Values[q14]
                  | q14 : int(1..1 + (b - a)), t_ExplicitVarSizeWithFlags_Flags[q14]])
         <= 6
             | t_ExplicitVarSizeWithFlags_Flags : matrix indexed by [int(1..1 + (b - a))] of bool,
               t_ExplicitVarSizeWithFlags_Values : matrix indexed by [int(1..1 + (b - a))] of int(a..b),
               and([t_ExplicitVarSizeWithFlags_Flags[q5 + 1] ->
                    t_ExplicitVarSizeWithFlags_Values[q5] < t_ExplicitVarSizeWithFlags_Values[q5 + 1]
                        | q5 : int(1..1 + (b - a) - 1)]),
               and([t_ExplicitVarSizeWithFlags_Flags[q6] = false -> t_ExplicitVarSizeWithFlags_Values[q6] = a
                        | q6 : int(1..1 + (b - a))]),
               and([t_ExplicitVarSizeWithFlags_Flags[q7 + 1] -> t_ExplicitVarSizeWithFlags_Flags[q7]
                        | q7 : int(1..1 + (b - a) - 1)])]),
    and([x_ExplicitVarSizeWithDummy[q1] < x_ExplicitVarSizeWithDummy[q1 + 1] \/ x_ExplicitVarSizeWithDummy[q1] = b + 1
             | q1 : int(1..1 + (b - a) - 1)]),
    and([x_ExplicitVarSizeWithDummy[q2] = b + 1 -> x_ExplicitVarSizeWithDummy[q2 + 1] = b + 1
             | q2 : int(1..1 + (b - a) - 1)]),
    n <= sum([toInt(x_ExplicitVarSizeWithDummy[q3] != b + 1) | q3 : int(1..1 + (b - a))])

