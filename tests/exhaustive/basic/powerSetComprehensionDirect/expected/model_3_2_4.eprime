language ESSENCE' 1.0

given n: int
given a: int
given b: int
find x_ExplicitVarSizeWithMarker_Marker: int(0..1 + (b - a))
find x_ExplicitVarSizeWithMarker_Values: matrix indexed by [int(1..1 + (b - a))] of int(a..b)
find x_ExplicitVarSizeWithDummy: matrix indexed by [int(1..1 + (b - a))] of int(a..b + 1)
such that
    and([and([or([q24 <= x_ExplicitVarSizeWithMarker_Marker /\
                  x_ExplicitVarSizeWithMarker_Values[q24] = t_ExplicitVarSizeWithFlags_Values[q22]
                      | q24 : int(1..1 + (b - a))])
                  | q22 : int(1..1 + (b - a)), t_ExplicitVarSizeWithFlags_Flags[q22]])
         ->
         sum([t_ExplicitVarSizeWithFlags_Values[q25]
                  | q25 : int(1..1 + (b - a)), t_ExplicitVarSizeWithFlags_Flags[q25]])
         <= 6
             | t_ExplicitVarSizeWithFlags_Flags : matrix indexed by [int(1..1 + (b - a))] of bool,
               t_ExplicitVarSizeWithFlags_Values : matrix indexed by [int(1..1 + (b - a))] of int(a..b),
               and([t_ExplicitVarSizeWithFlags_Flags[q16 + 1] ->
                    t_ExplicitVarSizeWithFlags_Values[q16] < t_ExplicitVarSizeWithFlags_Values[q16 + 1]
                        | q16 : int(1..1 + (b - a) - 1)]),
               and([t_ExplicitVarSizeWithFlags_Flags[q17] = false -> t_ExplicitVarSizeWithFlags_Values[q17] = a
                        | q17 : int(1..1 + (b - a))]),
               and([t_ExplicitVarSizeWithFlags_Flags[q18 + 1] -> t_ExplicitVarSizeWithFlags_Flags[q18]
                        | q18 : int(1..1 + (b - a) - 1)])]),
    and([q1 + 1 <= x_ExplicitVarSizeWithMarker_Marker ->
         x_ExplicitVarSizeWithMarker_Values[q1] < x_ExplicitVarSizeWithMarker_Values[q1 + 1]
             | q1 : int(1..1 + (b - a) - 1)]),
    and([q2 > x_ExplicitVarSizeWithMarker_Marker -> x_ExplicitVarSizeWithMarker_Values[q2] = a
             | q2 : int(1..1 + (b - a))]),
    n <= x_ExplicitVarSizeWithMarker_Marker,
    and([x_ExplicitVarSizeWithDummy[q4] < x_ExplicitVarSizeWithDummy[q4 + 1] \/ x_ExplicitVarSizeWithDummy[q4] = b + 1
             | q4 : int(1..1 + (b - a) - 1)]),
    and([x_ExplicitVarSizeWithDummy[q5] = b + 1 -> x_ExplicitVarSizeWithDummy[q5 + 1] = b + 1
             | q5 : int(1..1 + (b - a) - 1)]),
    n <= sum([toInt(x_ExplicitVarSizeWithDummy[q6] != b + 1) | q6 : int(1..1 + (b - a))]),
    and([x_ExplicitVarSizeWithDummy[q9] != b + 1 ->
         or([q11 <= x_ExplicitVarSizeWithMarker_Marker /\
             x_ExplicitVarSizeWithMarker_Values[q11] = x_ExplicitVarSizeWithDummy[q9]
                 | q11 : int(1..1 + (b - a))])
             | q9 : int(1..1 + (b - a))]),
    and([q13 <= x_ExplicitVarSizeWithMarker_Marker ->
         or([x_ExplicitVarSizeWithDummy[q15] != b + 1 /\
             x_ExplicitVarSizeWithDummy[q15] = x_ExplicitVarSizeWithMarker_Values[q13]
                 | q15 : int(1..1 + (b - a))])
             | q13 : int(1..1 + (b - a))])

