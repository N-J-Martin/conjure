language ESSENCE' 1.0

given n: int
given a: int
given b: int
find x_ExplicitVarSizeWithFlags_Flags: matrix indexed by [int(1..1 + (b - a))] of bool
find x_ExplicitVarSizeWithFlags_Values: matrix indexed by [int(1..1 + (b - a))] of int(a..b)
find x_ExplicitVarSizeWithDummy: matrix indexed by [int(1..1 + (b - a))] of int(a..b + 1)
such that
    and([and([or([x_ExplicitVarSizeWithFlags_Flags[q24] /\
                  x_ExplicitVarSizeWithFlags_Values[q24] = t_ExplicitVarSizeWithMarker_Values[q22]
                      | q24 : int(1..1 + (b - a))])
                  | q22 : int(1..1 + (b - a)), q22 <= t_ExplicitVarSizeWithMarker_Marker])
         ->
         sum([t_ExplicitVarSizeWithMarker_Values[q25]
                  | q25 : int(1..1 + (b - a)), q25 <= t_ExplicitVarSizeWithMarker_Marker])
         <= 6
             | t_ExplicitVarSizeWithMarker_Marker : int(0..1 + (b - a)),
               t_ExplicitVarSizeWithMarker_Values : matrix indexed by [int(1..1 + (b - a))] of int(a..b),
               and([q18 + 1 <= t_ExplicitVarSizeWithMarker_Marker ->
                    t_ExplicitVarSizeWithMarker_Values[q18] < t_ExplicitVarSizeWithMarker_Values[q18 + 1]
                        | q18 : int(1..1 + (b - a) - 1)]),
               and([q19 > t_ExplicitVarSizeWithMarker_Marker -> t_ExplicitVarSizeWithMarker_Values[q19] = a
                        | q19 : int(1..1 + (b - a))])]),
    and([x_ExplicitVarSizeWithFlags_Flags[q1 + 1] ->
         x_ExplicitVarSizeWithFlags_Values[q1] < x_ExplicitVarSizeWithFlags_Values[q1 + 1]
             | q1 : int(1..1 + (b - a) - 1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q2] = false -> x_ExplicitVarSizeWithFlags_Values[q2] = a
             | q2 : int(1..1 + (b - a))]),
    and([x_ExplicitVarSizeWithFlags_Flags[q3 + 1] -> x_ExplicitVarSizeWithFlags_Flags[q3]
             | q3 : int(1..1 + (b - a) - 1)]),
    n <= sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q4]) | q4 : int(1..1 + (b - a))]),
    and([x_ExplicitVarSizeWithDummy[q6] < x_ExplicitVarSizeWithDummy[q6 + 1] \/ x_ExplicitVarSizeWithDummy[q6] = b + 1
             | q6 : int(1..1 + (b - a) - 1)]),
    and([x_ExplicitVarSizeWithDummy[q7] = b + 1 -> x_ExplicitVarSizeWithDummy[q7 + 1] = b + 1
             | q7 : int(1..1 + (b - a) - 1)]),
    n <= sum([toInt(x_ExplicitVarSizeWithDummy[q8] != b + 1) | q8 : int(1..1 + (b - a))]),
    and([x_ExplicitVarSizeWithDummy[q11] != b + 1 ->
         or([x_ExplicitVarSizeWithFlags_Flags[q13] /\
             x_ExplicitVarSizeWithFlags_Values[q13] = x_ExplicitVarSizeWithDummy[q11]
                 | q13 : int(1..1 + (b - a))])
             | q11 : int(1..1 + (b - a))]),
    and([x_ExplicitVarSizeWithFlags_Flags[q15] ->
         or([x_ExplicitVarSizeWithDummy[q17] != b + 1 /\
             x_ExplicitVarSizeWithDummy[q17] = x_ExplicitVarSizeWithFlags_Values[q15]
                 | q17 : int(1..1 + (b - a))])
             | q15 : int(1..1 + (b - a))])

