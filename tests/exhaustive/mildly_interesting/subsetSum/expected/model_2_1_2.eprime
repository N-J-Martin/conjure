language ESSENCE' 1.0

given s: int
given fin1: int
given fin2: int
given fin3: int
given nums_Explicit: matrix indexed by [int(1..fin1)] of int(fin2..fin3)
letting let1 be fin1
letting let2 be [nums_Explicit[q24] | q24 : int(1..fin1)]
find x_ExplicitVarSizeWithFlags_Flags: matrix indexed by [int(1..let1)] of bool
find x_ExplicitVarSizeWithFlags_Values: matrix indexed by [int(1..let1)] of int(let2)
find x_ExplicitVarSizeWithMarker_Marker: int(0..let1)
find x_ExplicitVarSizeWithMarker_Values: matrix indexed by [int(1..let1)] of int(let2)
branching on
    [x_ExplicitVarSizeWithMarker_Marker, x_ExplicitVarSizeWithMarker_Values, x_ExplicitVarSizeWithFlags_Flags,
     x_ExplicitVarSizeWithFlags_Values]
such that
    sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q31]) | q31 : int(1..let1)]) <= fin1,
    and([x_ExplicitVarSizeWithFlags_Flags[q27] ->
         or([nums_Explicit[q29] = x_ExplicitVarSizeWithFlags_Values[q27] | q29 : int(1..fin1)])
             | q27 : int(1..let1)]),
    s =
    sum([toInt(q25 <= x_ExplicitVarSizeWithMarker_Marker) * catchUndef(x_ExplicitVarSizeWithMarker_Values[q25], 0)
             | q25 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q2 + 1] ->
         x_ExplicitVarSizeWithFlags_Values[q2] < x_ExplicitVarSizeWithFlags_Values[q2 + 1]
             | q2 : int(1..let1 - 1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q3] = false -> x_ExplicitVarSizeWithFlags_Values[q3] = min(let2)
             | q3 : int(1..let1)]),
    and([x_ExplicitVarSizeWithFlags_Flags[q4 + 1] -> x_ExplicitVarSizeWithFlags_Flags[q4] | q4 : int(1..let1 - 1)]),
    1 <= sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q5]) | q5 : int(1..let1)]),
    sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q5]) | q5 : int(1..let1)]) <= let1,
    and([q7 + 1 <= x_ExplicitVarSizeWithMarker_Marker ->
         x_ExplicitVarSizeWithMarker_Values[q7] < x_ExplicitVarSizeWithMarker_Values[q7 + 1]
             | q7 : int(1..let1 - 1)]),
    and([q8 > x_ExplicitVarSizeWithMarker_Marker -> x_ExplicitVarSizeWithMarker_Values[q8] = min(let2)
             | q8 : int(1..let1)]),
    1 <= x_ExplicitVarSizeWithMarker_Marker,
    x_ExplicitVarSizeWithMarker_Marker <= let1,
    x_ExplicitVarSizeWithMarker_Marker = sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q11]) | q11 : int(1..let1)]),
    x_ExplicitVarSizeWithMarker_Marker <= sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q14]) | q14 : int(1..let1)]),
    and([q15 <= x_ExplicitVarSizeWithMarker_Marker ->
         or([x_ExplicitVarSizeWithFlags_Flags[q17] /\
             x_ExplicitVarSizeWithFlags_Values[q17] = x_ExplicitVarSizeWithMarker_Values[q15]
                 | q17 : int(1..let1)])
             | q15 : int(1..let1)]),
    sum([toInt(x_ExplicitVarSizeWithFlags_Flags[q23]) | q23 : int(1..let1)]) <= x_ExplicitVarSizeWithMarker_Marker,
    and([x_ExplicitVarSizeWithFlags_Flags[q19] ->
         or([q21 <= x_ExplicitVarSizeWithMarker_Marker /\
             x_ExplicitVarSizeWithMarker_Values[q21] = x_ExplicitVarSizeWithFlags_Values[q19]
                 | q21 : int(1..let1)])
             | q19 : int(1..let1)])

